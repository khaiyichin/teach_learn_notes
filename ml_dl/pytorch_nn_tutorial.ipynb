{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/khaiyichin/21f114d7f06027eabaaa407c5e942174/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2BThsV_Ew9T"
      },
      "source": [
        "# Neural network tutorial with PyTorch\n",
        "This brief tutorial provides instruction on how to:\n",
        "\n",
        "1. obtain prepared data offered by PyTorch,\n",
        "2. set up a neural network class,\n",
        "3. train the neural network, and\n",
        "4. save/load the models to train on different devices.\n",
        "\n",
        "Note: training the neural networks in this tutorial will require GPU; for easy GPU access simply run this in Google Colab. Once in Colab, go to `Edit` > `Notebook Settings` which will generate a pop-up. In the pop-up select `GPU` as the `Hardware accelerator`.\n",
        "\n",
        "---\n",
        "\n",
        "The materials here are adapted from a tutorial provided by the WPI DS595: Reinforcement Learning class on using PyTorch.\n",
        "\n",
        "Reference on saving/loading models: https://debuggercafe.com/effective-model-saving-and-resuming-training-in-pytorch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PtFG6osUcMUV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP2LnuhwcMUd"
      },
      "source": [
        "### Step 1. Prepare data.\n",
        "2 things to keep in mind when preprocessing the data for training:\n",
        "* Tensor shape\n",
        "* Tensor datatype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvNP6tVDJYF6"
      },
      "source": [
        "Download the CIFAR 10 data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR2AbBp5cMUd",
        "outputId": "9091bdeb-b4f4-485e-f417-68cd599e813c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "original dtype: <class 'numpy.ndarray'>\n",
            "original shape: (50000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "# Prepare Data\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "print('original dtype:',type(trainset.data))\n",
        "print('original shape:',trainset.data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KIpJAryJSCT"
      },
      "source": [
        "Example on how to create a minibatch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_qOeuMa_cMUg",
        "outputId": "9fc98cc6-397e-4b86-b7c6-bdba4b0ba570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 3, 32, 32])\n",
            "torch.float64\n"
          ]
        }
      ],
      "source": [
        "def batch(data,batch_size):\n",
        "    minibatch = random.sample(data, batch_size)\n",
        "    minibatch = np.array(minibatch).transpose(0,3,1,2)\n",
        "    minibatch = torch.tensor(minibatch/ 255.0)\n",
        "    return minibatch\n",
        "\n",
        "minibatch = batch(list(trainset.data),32)\n",
        "print(minibatch.shape)\n",
        "print(minibatch.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1GSCqqkcMUn"
      },
      "source": [
        "### Step 2. Define a neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZABkTknE1Cf"
      },
      "source": [
        "We define our desired neural network architecture as a class that inherits from `nn.Module`; this is so that core PyTorch neural network methods are available to us.\n",
        "\n",
        "In the `__init__` function the parent methods and attributes are inherited first before the definition of desired neural network blocks.\n",
        "\n",
        "In the `forward` method, the network structure is set up based on the defined blocks in `__init__`. This is the method that executes forward propagation in the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "c9dx-W7kcMUo"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    \"\"\"Neural network class.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__() # inherit parent methods and attributes\n",
        "\n",
        "        # Define layers\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5) # convolves 3 -> 6 channels with a 5x5 kernel\n",
        "        self.pool = nn.MaxPool2d(2, 2) # pools 2x2 elements of the input with a stride of 2\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5) # convolves 6 -> 16 channels with a 5x5 kernel\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # fully connected layer with 120 nodes\n",
        "        self.fc2 = nn.Linear(120, 84) # fully connected layer with 84 nodes\n",
        "        self.fc3 = nn.Linear(84, 10) # fully connected layer with 10 nodes\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Executes forward propagation of the network.\n",
        "\n",
        "        Processes x to generate a prediction.\n",
        "\n",
        "        This method should not be called directly, instead use the class as a\n",
        "        function, e.g.,\n",
        "            net = Net()\n",
        "            ...\n",
        "            y = net(x) # will output prediction based on input tensor x\n",
        "\n",
        "        Args:\n",
        "            x: A PyTorch tensor input.\n",
        "\n",
        "        Returns:\n",
        "            A prediction based on the input x.\n",
        "        \"\"\"\n",
        "        # Convolution block 1\n",
        "        x = self.pool(F.relu(self.conv1(x))) # 32x32x3 -> 28x28x6 -> 14x14x6\n",
        "\n",
        "        # Convolution block 2\n",
        "        x = self.pool(F.relu(self.conv2(x))) # 14x14x6 -> 10x10x16 -> 5x5x16\n",
        "\n",
        "        # Flatten into 1D\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        # Output layer\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7aNKeNicMUv"
      },
      "source": [
        "### Step 3. Train on GPU, then save model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9JCwpaPJ35K"
      },
      "source": [
        "Show that the GPU device is available:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpnyBCBkcMUv",
        "outputId": "3c62aa7b-dc29-4ca7-858b-9ba42642f510",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyJGe_U8KDln"
      },
      "source": [
        "Train the network on the CIFAR10 dataset for 1 epoch using the GPU, then save the trained model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz8d4a5-cMUw",
        "outputId": "0bf23b5b-87e4-45ba-f9a5-9f959e20a20c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with GPU\n",
            "[1,  2000] loss: 2.191\n",
            "[1,  4000] loss: 1.836\n",
            "[1,  6000] loss: 1.661\n",
            "[1,  8000] loss: 1.569\n",
            "[1, 10000] loss: 1.492\n",
            "[1, 12000] loss: 1.467\n",
            "Finished Training in 69.98760816800001 s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "print(\"Training with GPU for the 1st epoch\")\n",
        "\n",
        "# Initialize neural network model and  optimizer\n",
        "gpu_net = Net().to(device)\n",
        "gpu_optimizer = optim.SGD(gpu_net.parameters(), lr=0.001, momentum=0.9)\n",
        "gpu_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "t = time.process_time()\n",
        "\n",
        "# Train model for 1 epoch\n",
        "for epoch in range(1):  # can loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        ####################################################\n",
        "        # tensor\n",
        "        # batch_size, channel, H, W\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        gpu_optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = gpu_net(inputs)\n",
        "        loss = gpu_criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        gpu_optimizer.step()\n",
        "        ####################################################\n",
        "        \n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training in ' + str(time.process_time() - t) + ' s')\n",
        "\n",
        "# Save model, optimizer and loss function\n",
        "PATH_1 = './test_model.pth'\n",
        "\n",
        "torch.save({\n",
        "            'model_state_dict': gpu_net.state_dict(),\n",
        "            'optimizer_state_dict': gpu_optimizer.state_dict(),\n",
        "            'loss': gpu_criterion,\n",
        "            }, PATH_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNPleRMAXQ-d"
      },
      "source": [
        "### Step 4. Load model to train on CPU, then save it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5acZAReGQB6_",
        "outputId": "c5cce5eb-4ea0-4b5b-e788-238d43aadefc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with CPU\n",
            "[1,  2000] loss: 1.386\n",
            "[1,  4000] loss: 1.365\n",
            "[1,  6000] loss: 1.359\n",
            "[1,  8000] loss: 1.321\n",
            "[1, 10000] loss: 1.289\n",
            "[1, 12000] loss: 1.290\n",
            "Finished Training in 61.85360124400006 s\n"
          ]
        }
      ],
      "source": [
        "# Load model to train with CPU\n",
        "print(\"Training with CPU for the 2nd epoch\")\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# Initialize empty containers to load our model and optimizer to\n",
        "cpu_net = Net().to(device)\n",
        "cpu_optimizer = optim.SGD(cpu_net.parameters(), lr=0.001, momentum=0.9)\n",
        "cpu_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Load required objects\n",
        "checkpoint = torch.load(PATH_1, map_location=device)\n",
        "\n",
        "cpu_net.load_state_dict(checkpoint['model_state_dict'])\n",
        "cpu_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "cpu_criterion = checkpoint['loss']\n",
        "cpu_net.train() # set model to training mode\n",
        "\n",
        "t = time.process_time()\n",
        "\n",
        "# Continue training model for another epoch\n",
        "for epoch in range(1):  # can loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        ####################################################\n",
        "        # tensor\n",
        "        # batch_size, channel, H, W\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        cpu_optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = cpu_net(inputs)\n",
        "        loss = cpu_criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        cpu_optimizer.step()\n",
        "        ####################################################\n",
        "        \n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training in ' + str(time.process_time() - t) + ' s')\n",
        "\n",
        "# Save model, optimizer and loss function\n",
        "PATH_2 = './test_model_2.pth'\n",
        "\n",
        "torch.save({\n",
        "            'model_state_dict': cpu_net.state_dict(),\n",
        "            'optimizer_state_dict': cpu_optimizer.state_dict(),\n",
        "            'loss': cpu_criterion,\n",
        "            }, PATH_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASJeX-tRK-7f"
      },
      "source": [
        "### Step 5. Load model to train on GPU for the 3rd and final epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPsjCEVPLhRP",
        "outputId": "82249877-92cd-4838-f824-54fa4e6a51b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with GPU\n",
            "[1,  2000] loss: 1.226\n",
            "[1,  4000] loss: 1.214\n",
            "[1,  6000] loss: 1.223\n",
            "[1,  8000] loss: 1.210\n",
            "[1, 10000] loss: 1.210\n",
            "[1, 12000] loss: 1.179\n",
            "Finished Training in 70.29780777899998 s\n"
          ]
        }
      ],
      "source": [
        "# Load model to train with CPU\n",
        "print(\"Training with GPU for the 3rd epoch\")\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "# Initialize empty containers to load our model and optimizers to\n",
        "final_net = Net().to(device)\n",
        "final_optimizer = optim.SGD(final_net.parameters(), lr=0.001, momentum=0.9)\n",
        "final_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Load required objects\n",
        "checkpoint = torch.load(PATH_2, map_location=device)\n",
        "\n",
        "final_net.load_state_dict(checkpoint['model_state_dict'])\n",
        "final_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "final_criterion = checkpoint['loss']\n",
        "final_net.train() # set model to training mode\n",
        "\n",
        "t = time.process_time()\n",
        "\n",
        "# Train model for another epoch\n",
        "for epoch in range(1):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        ####################################################\n",
        "        # tensor\n",
        "        # batch_size, channel, H, W\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        final_optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = final_net(inputs)\n",
        "        loss = final_criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        final_optimizer.step()\n",
        "        ####################################################\n",
        "        \n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training in ' + str(time.process_time() - t) + ' s')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "pytorch_nn_tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
